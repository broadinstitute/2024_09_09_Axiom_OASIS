{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process CNN embeddings from Ray/Bram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import h5py\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "cpg0037_path = \"/Users/jewald/Desktop/cpg0037\"\n",
    "sc_path = \"/Users/jewald/Desktop/cpg0037/axiom_merged_sc.parquet\"\n",
    "well_input_path = \"/Users/jewald/Desktop/cpg0037/well_means_medians.h5\"\n",
    "well_output_path = \"/Users/jewald/Desktop/cpg0037/axiom_merged_well.parquet\"\n",
    "meta_path = \"/Users/jewald/repos/2024_09_09_Axiom_OASIS/1_snakemake/inputs/metadata/metadata.parquet\"\n",
    "\n",
    "plates = os.listdir(cpg0037_path)\n",
    "plates = [i for i in plates if \"plate\" in i]\n",
    "\n",
    "column_names = [\"Metadata_Index\"] + [f\"f_{str(i).zfill(3)}\" for i in range(1, 673)]\n",
    "\n",
    "final_names = [\"Metadata_Plate\", \"Metadata_Well\"] + [f\"f_{str(i).zfill(3)}\" for i in range(1, 673)]\n",
    "\n",
    "data_types = [pa.string(), pa.string()] + [pa.float32()] * 672\n",
    "schema = pa.schema(list(zip(final_names, data_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [47:32<00:00, 41.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# Implement writing in chunks\n",
    "writer = pq.ParquetWriter(sc_path, schema, compression='gzip')\n",
    "for plate in tqdm(plates):\n",
    "    plate_nm = plate.replace(\"plate_\", \"\")\n",
    "    plate_nm = plate_nm.replace(\".h5\", \"\")\n",
    "\n",
    "    plate_path = f\"{cpg0037_path}/{plate}\"\n",
    "\n",
    "    with h5py.File(plate_path, 'r') as h5_file:\n",
    "        meta = list(h5_file[\"meta/Metadata_Well\"][:])\n",
    "        meta = [i.decode() for i in meta]\n",
    "        meta_df = pl.DataFrame({\n",
    "            \"Metadata_Plate\": plate_nm,\n",
    "            \"Metadata_Well\": meta,\n",
    "            \"Metadata_Index\": range(len(meta)),\n",
    "        })\n",
    "\n",
    "        data = h5_file[\"deepprofiler\"][:]\n",
    "        data_df = pl.DataFrame(data, schema=column_names).with_columns(\n",
    "            pl.col(\"Metadata_Index\").cast(pl.Int64).alias(\"Metadata_Index\"),\n",
    "        )\n",
    "        data_df = meta_df.join(data_df, on=\"Metadata_Index\").drop(\"Metadata_Index\").to_pandas()\n",
    "\n",
    "        # write to parquet\n",
    "        table = pa.Table.from_pandas(data_df, preserve_index=False)\n",
    "        writer.write_table(table)\n",
    "    \n",
    "    # close parquet writer\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create well-aggregated profiles\n",
    "well_df = pl.scan_parquet(sc_path).group_by([\"Metadata_Plate\", \"Metadata_Well\"]).agg([\n",
    "    pl.col(\"*\").exclude([\"Metadata_Plate\", \"Metadata_Well\"]).median(),\n",
    "]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate well-level data\n",
    "with h5py.File(well_input_path, 'r') as h5_file:\n",
    "    meta = list(h5_file[\"meta/Metadata_Well\"][:])\n",
    "    meta = [i.decode() for i in meta]\n",
    "    plates = list(h5_file[\"meta/Metadata_Plate\"][:])\n",
    "    plates = [i.decode() for i in plates]\n",
    "    meta_df = pl.DataFrame({\n",
    "        \"Metadata_Plate\": plates,\n",
    "        \"Metadata_Well\": meta,\n",
    "    })\n",
    "\n",
    "    data = h5_file[\"deepprofiler_median\"][:]\n",
    "    data_df = pl.DataFrame(data, schema=[f\"f_{str(i).zfill(3)}\" for i in range(1, 673)])\n",
    "\n",
    "data_df = pl.concat([meta_df, data_df], how=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pl.read_parquet(meta_path)\n",
    "merge_df = meta.join(data_df, on=[\"Metadata_Plate\", \"Metadata_Well\"])\n",
    "merge_df.write_parquet(\"/Users/jewald/repos/2024_09_09_Axiom_OASIS/1_snakemake/inputs/profiles/cpcnn/raw.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "axiom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
